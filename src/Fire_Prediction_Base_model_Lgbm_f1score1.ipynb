{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score , precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, gc, warnings, random, datetime, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('PJT002_train.csv')\n",
    "val = pd.read_csv('PJT002_validation.csv')\n",
    "test = pd.read_csv('PJT002_test.csv')\n",
    "sub = pd.read_csv('PJT002_submission.csv')\n",
    "data = pd.concat([train, val, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_copy(data):\n",
    "    data_ = data.copy()\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['name_1'] = data['emd_nm'].str[5:8]\n",
    "\n",
    "data['name_4'] = data['name_1'].str[2]\n",
    "\n",
    "data['name_2'] = data['emd_nm'].str[::-1].str[:].str[2]+data['emd_nm'].str[::-1].str[:].str[1]+data['emd_nm'].str[::-1].str[:].str[0]\n",
    "\n",
    "data['name_3'] =data['emd_nm'].str[::-1].str[:].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat)\n",
    "    return 'f1_score', f1_score(y_true, y_hat), True\n",
    "\n",
    "def lgbmgo(data_, train, test, rm_cols):\n",
    "\n",
    "    train_ = data_[:len(train)+2500]\n",
    "    val_ = data_[len(train)+2500:-len(test)]\n",
    "    test_ = data_[-len(test):]\n",
    "    dataset = [train_, val_, test_]\n",
    "\n",
    "    for df in dataset:\n",
    "        categorical_cols1 = df.select_dtypes(['object']).columns\n",
    "        for col in categorical_cols1:\n",
    "            df[col] = pd.Categorical(df[col]).codes\n",
    "    train_.drop(rm_cols,1,inplace=True)\n",
    "    val_.drop(rm_cols,1,inplace=True)\n",
    "    test_.drop(rm_cols,1,inplace=True)\n",
    "    X_train = train_.drop('fr_yn', 1)\n",
    "    y_train = train_['fr_yn']\n",
    "    X_val = val_.drop('fr_yn', 1)\n",
    "    y_val = val_['fr_yn']\n",
    "    X_test = test_.drop(columns = ['fr_yn'])\n",
    "    \n",
    "    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape)\n",
    "    #모델 생성 및 학습\n",
    "    params = {\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 250,\n",
    "                    'max_depth':8,\n",
    "                    'n_estimators':10000,\n",
    "                    'seed' :SEED,\n",
    "                }\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train ,label= y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, label= y_val)\n",
    "    y_prob = np.zeros((X_test.shape[0]))\n",
    "\n",
    "    model = lgb.train(params, lgb_train, feval=lgb_f1_score, valid_sets=[lgb_train, lgb_eval], early_stopping_rounds=300, verbose_eval=100)\n",
    "    \n",
    "    y_pred = model.predict(X_val)[:]\n",
    "    val_pred = pd.DataFrame(y_pred)\n",
    "    val_pred[0] = val_pred[0]>0.5\n",
    "    val_pred[0] = val_pred[0].map({False:0,True:1})\n",
    "\n",
    "    score = precision_score(y_val, val_pred[0])\n",
    "    score2 = accuracy_score(y_val, val_pred[0])\n",
    "\n",
    "    score3 = recall_score(y_val, val_pred[0])\n",
    "    score4 = f1_score(y_val, val_pred[0])\n",
    "\n",
    "    print('AUC_score :', score,'| Acc_score :', score2,'| recall_score :', score3,'| f1_score :', score4)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-48c15113bcdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscore3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mscore4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_val' is not defined"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(y_val, val_pred[0])\n",
    "score2 = accuracy_score(y_val, val_pred[0])\n",
    "\n",
    "score3 = recall_score(y_val, val_pred[0])\n",
    "score4 = f1_score(y_val, val_pred[0])\n",
    "\n",
    "print('precision_score :', score,'| Acc_score :', score2,'| recall_score :', score3,'| f1_score :', score4)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ = data.copy()\n",
    "no_fe = lgbmgo(data_, train, test,rm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dt_of_fr'] = pd.to_datetime(data['dt_of_fr'])\n",
    "data['DT_hour'] = (data['dt_of_fr'].dt.hour).astype(np.int8)\n",
    "#data['DT_Y'] = (data['dt_of_fr'].dt.year).astype(np.int8)\n",
    "# data['DT_day_week'] = (data['dt_of_fr'].dt.dayofweek).astype(np.int8)\n",
    "# data['DT_day_month'] = (data['dt_of_fr'].dt.day).astype(np.int8)\n",
    "data['DT_M'] = (data['dt_of_fr'].dt.month).astype(np.int8)\n",
    "# data = data.drop('dt_of_fr',axis = 1)\n",
    "rm_cols += ['dt_of_fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dt_of_athrztn'].fillna(9999, inplace=True)\n",
    "data['dt_of_athrztn_year'] = data['dt_of_athrztn'].astype(str).str[:4].astype(int)\n",
    "#data['diff_athrztn_frY'] = data['DT_Y']-data['dt_of_athrztn_year']\n",
    "# data = data.drop(['dt_of_athrztn','DT_Y'], axis = 1)\n",
    "rm_cols += ['dt_of_athrztn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(1600,2019, 20)\n",
    "data['dt_of_athrztn_year2'] = np.digitize(data['dt_of_athrztn_year'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'dt_of_fr', 'dt_of_athrztn']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61699, 184) (4398, 184) (61699,) (4398,) (2957, 184)\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[100]\ttraining's f1_score: 0.249038\tvalid_1's f1_score: 0.324222\n",
      "[200]\ttraining's f1_score: 0.449573\tvalid_1's f1_score: 0.457547\n",
      "[300]\ttraining's f1_score: 0.514635\tvalid_1's f1_score: 0.470053\n",
      "[400]\ttraining's f1_score: 0.541843\tvalid_1's f1_score: 0.467318\n",
      "[500]\ttraining's f1_score: 0.563178\tvalid_1's f1_score: 0.469708\n",
      "[600]\ttraining's f1_score: 0.580427\tvalid_1's f1_score: 0.472782\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's f1_score: 0.522492\tvalid_1's f1_score: 0.475546\n",
      "AUC_score : 0.6515463917525773 | Acc_score : 0.841518872214643 | recall_score : 0.3744075829383886 | f1_score : 0.4755455229495861\n"
     ]
    }
   ],
   "source": [
    "data_ = data.copy()\n",
    "fe_time = lgbmgo(data_, train, test,rm_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['danger1'] = data['no_tbc_zn_dstnc'] - data['tbc_rtl_str_dstnc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['prevent1'] = data['cctv_in_100m'] + data['fr_wthr_fclt_in_100m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm_cols.remove('DT_Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linspace(-19175,9795, 300)\n",
    "# data['danger1'] = np.digitize(data['danger1'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linspace(0,16164, 160)\n",
    "# data['no_tbc_zn_dstnc'] = np.digitize(data['no_tbc_zn_dstnc'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linspace(0,24000, 240)\n",
    "# data['tbc_rtl_str_dstnc'] = np.digitize(data['tbc_rtl_str_dstnc'], bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.copy()\n",
    "fe_time_ath_ttl_dan_pre = lgbmgo(data_, train, test,rm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['cctv_in_100m'][data['cctv_in_100m'] >= 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['fr_wthr_fclt_in_100m'][data['fr_wthr_fclt_in_100m'] >= 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_ = data.copy()\n",
    "# fe_time_ath_ttl_dan_pre = lgbmgo(data_, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61699, 184) (1898, 184) (61699,) (1898,) (2957, 184)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's f1_score: 0.249038\tvalid_1's f1_score: 0.324649\n",
      "[200]\ttraining's f1_score: 0.449573\tvalid_1's f1_score: 0.469218\n",
      "[300]\ttraining's f1_score: 0.514635\tvalid_1's f1_score: 0.477419\n",
      "[400]\ttraining's f1_score: 0.541843\tvalid_1's f1_score: 0.472089\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's f1_score: 0.522492\tvalid_1's f1_score: 0.481541\n",
      "precision : 0.6607929515418502 | Acc_score : 0.8298208640674394 | recall_score : 0.3787878787878788 | f1_score : 0.48154093097913325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    train = data[:len(train)+2500]\n",
    "    val = data[len(train)+2500:-len(test)]\n",
    "    test = data[-len(test):]\n",
    "    dataset = [train, val, test]\n",
    "\n",
    "    for df in dataset:\n",
    "        categorical_cols1 = df.select_dtypes(['object']).columns\n",
    "        for col in categorical_cols1:\n",
    "            df[col] = pd.Categorical(df[col]).codes\n",
    "    train.drop(rm_cols,1,inplace=True)\n",
    "    val.drop(rm_cols,1,inplace=True)\n",
    "    test.drop(rm_cols,1,inplace=True)\n",
    "    X_train = train.drop('fr_yn', 1)\n",
    "    y_train = train['fr_yn']\n",
    "    X_val = val.drop('fr_yn', 1)\n",
    "    y_val = val['fr_yn']\n",
    "    X_test = test.drop(columns = ['fr_yn'])\n",
    "    \n",
    "    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape)\n",
    "    #모델 생성 및 학습\n",
    "    params = {\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 250,\n",
    "                    'max_depth':8,\n",
    "                    'n_estimators':10000,\n",
    "                    'seed' :SEED,\n",
    "                }\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train ,label= y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, label= y_val)\n",
    "    y_prob = np.zeros((X_test.shape[0]))\n",
    "\n",
    "    model = lgb.train(params, lgb_train, feval=lgb_f1_score, valid_sets=[lgb_train, lgb_eval], early_stopping_rounds=100, verbose_eval=100)\n",
    "    \n",
    "    y_pred = model.predict(X_val)[:]\n",
    "    val_pred = pd.DataFrame(y_pred)\n",
    "    val_pred[0] = val_pred[0]>0.5\n",
    "    val_pred[0] = val_pred[0].map({False:0,True:1})\n",
    "\n",
    "    score = precision_score(y_val, val_pred[0])\n",
    "    score2 = accuracy_score(y_val, val_pred[0])\n",
    "\n",
    "    score3 = recall_score(y_val, val_pred[0])\n",
    "    score4 = f1_score(y_val, val_pred[0])\n",
    "\n",
    "    print('precision :', score,'| Acc_score :', score2,'| recall_score :', score3,'| f1_score :', score4)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "\n",
    "    tt_df = tt_df[[target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "    oof = np.zeros(len(tr_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            vl_data = lgb.Dataset(P, label=P_y) \n",
    "        else:\n",
    "            vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            feval=lgb_f1_score,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "        oof_preds = estimator.predict(vl_x)\n",
    "        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n",
    "        \n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    print('OOF f1score:', f1_score(y, oof))\n",
    "    \n",
    "    return tt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = pd.DataFrame(y)\n",
    "val_pred[0] = val_pred[0]>0.5\n",
    "val_pred[0] = val_pred[0].map({False:0,True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['fr_yn'] = val_pred[0]\n",
    "sub['fr_yn'] = sub['fr_yn'].map({0:'N', 1:'Y'})\n",
    "sub.to_csv('tmddnjs94_1128_nofe진우NEW 101.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
